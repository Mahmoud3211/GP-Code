{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\mahmo\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\mahmo\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\mahmo\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\mahmo\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\mahmo\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\mahmo\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\mahmo\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\mahmo\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\mahmo\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\mahmo\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\mahmo\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\mahmo\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imutils, sys, os, inspect\n",
    "from keras.models import load_model\n",
    "import multiprocessing, threading\n",
    "import tensorflow as tf\n",
    "sys.path.insert(0,\"D:\\\\College\\\\2020\\\\GP\\\\Coding\\\\GP-Code\") \n",
    "\n",
    "from data import DataSet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.2.4', '1.14.0')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "keras.__version__, tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0906 16:12:05.542775 16500 deprecation_wrapper.py:119] From C:\\Users\\mahmo\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0906 16:12:05.564682 16500 deprecation_wrapper.py:119] From C:\\Users\\mahmo\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0906 16:12:05.613576 16500 deprecation_wrapper.py:119] From C:\\Users\\mahmo\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:245: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0906 16:12:05.615546 16500 deprecation_wrapper.py:119] From C:\\Users\\mahmo\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0906 16:12:05.617543 16500 deprecation_wrapper.py:119] From C:\\Users\\mahmo\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0906 16:12:05.674389 16500 deprecation_wrapper.py:119] From C:\\Users\\mahmo\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0906 16:12:05.955661 16500 deprecation_wrapper.py:119] From C:\\Users\\mahmo\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0906 16:12:07.556357 16500 deprecation.py:506] From C:\\Users\\mahmo\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_1 (TimeDist (None, 30, 150, 150, 32)  4736      \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 30, 150, 150, 32)  128       \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 30, 150, 150, 32)  0         \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 30, 148, 148, 32)  9248      \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 30, 148, 148, 32)  128       \n",
      "_________________________________________________________________\n",
      "time_distributed_6 (TimeDist (None, 30, 148, 148, 32)  0         \n",
      "_________________________________________________________________\n",
      "time_distributed_7 (TimeDist (None, 30, 74, 74, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_8 (TimeDist (None, 30, 74, 74, 64)    18496     \n",
      "_________________________________________________________________\n",
      "time_distributed_9 (TimeDist (None, 30, 74, 74, 64)    256       \n",
      "_________________________________________________________________\n",
      "time_distributed_10 (TimeDis (None, 30, 74, 74, 64)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_11 (TimeDis (None, 30, 74, 74, 64)    36928     \n",
      "_________________________________________________________________\n",
      "time_distributed_12 (TimeDis (None, 30, 74, 74, 64)    256       \n",
      "_________________________________________________________________\n",
      "time_distributed_13 (TimeDis (None, 30, 74, 74, 64)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_14 (TimeDis (None, 30, 37, 37, 64)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_15 (TimeDis (None, 30, 37, 37, 128)   73856     \n",
      "_________________________________________________________________\n",
      "time_distributed_16 (TimeDis (None, 30, 37, 37, 128)   512       \n",
      "_________________________________________________________________\n",
      "time_distributed_17 (TimeDis (None, 30, 37, 37, 128)   0         \n",
      "_________________________________________________________________\n",
      "time_distributed_18 (TimeDis (None, 30, 37, 37, 128)   147584    \n",
      "_________________________________________________________________\n",
      "time_distributed_19 (TimeDis (None, 30, 37, 37, 128)   512       \n",
      "_________________________________________________________________\n",
      "time_distributed_20 (TimeDis (None, 30, 37, 37, 128)   0         \n",
      "_________________________________________________________________\n",
      "time_distributed_21 (TimeDis (None, 30, 18, 18, 128)   0         \n",
      "_________________________________________________________________\n",
      "time_distributed_22 (TimeDis (None, 30, 18, 18, 256)   295168    \n",
      "_________________________________________________________________\n",
      "time_distributed_23 (TimeDis (None, 30, 18, 18, 256)   1024      \n",
      "_________________________________________________________________\n",
      "time_distributed_24 (TimeDis (None, 30, 18, 18, 256)   0         \n",
      "_________________________________________________________________\n",
      "time_distributed_25 (TimeDis (None, 30, 18, 18, 256)   590080    \n",
      "_________________________________________________________________\n",
      "time_distributed_26 (TimeDis (None, 30, 18, 18, 256)   1024      \n",
      "_________________________________________________________________\n",
      "time_distributed_27 (TimeDis (None, 30, 18, 18, 256)   0         \n",
      "_________________________________________________________________\n",
      "time_distributed_28 (TimeDis (None, 30, 9, 9, 256)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_29 (TimeDis (None, 30, 9, 9, 512)     1180160   \n",
      "_________________________________________________________________\n",
      "time_distributed_30 (TimeDis (None, 30, 9, 9, 512)     2048      \n",
      "_________________________________________________________________\n",
      "time_distributed_31 (TimeDis (None, 30, 9, 9, 512)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_32 (TimeDis (None, 30, 9, 9, 512)     2359808   \n",
      "_________________________________________________________________\n",
      "time_distributed_33 (TimeDis (None, 30, 9, 9, 512)     2048      \n",
      "_________________________________________________________________\n",
      "time_distributed_34 (TimeDis (None, 30, 9, 9, 512)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_35 (TimeDis (None, 30, 4, 4, 512)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_36 (TimeDis (None, 30, 8192)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 30, 512)           17303552  \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 128)               295424    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 29)                3741      \n",
      "=================================================================\n",
      "Total params: 22,326,717\n",
      "Trainable params: 22,322,749\n",
      "Non-trainable params: 3,968\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sequence_list = []\n",
    "\n",
    "#capturing live video frames\n",
    "model_frames_num = 30\n",
    "realtime_frames = 120\n",
    "saved_model = 'D:/College/2020/GP/Coding/GP-Code/data/checkpoints/lrcn-images.385-0.111.hdf5'\n",
    "model = load_model(saved_model, compile=False)\n",
    "graph = tf.get_default_graph()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max frames => 300\n"
     ]
    }
   ],
   "source": [
    "data = DataSet(seq_length=model_frames_num, class_limit=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions(frames, model):\n",
    "    assert len(frames) == model_frames_num\n",
    "    with graph.as_default():\n",
    "        prediction = model.predict(np.expand_dims(frames, axis=0))\n",
    "        pred = data.print_class_from_prediction(np.squeeze(prediction, axis=0))\n",
    "        print(pred)\n",
    "        return pred[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of frames to pass before changing the frame to compare the current\n",
    "# frame against\n",
    "FRAMES_TO_PERSIST = 10\n",
    "\n",
    "# Minimum boxed area for a detected motion to count as actual motion\n",
    "# Use to filter out noise or small objects\n",
    "MIN_SIZE_FOR_MOVEMENT = 2000\n",
    "\n",
    "# Minimum length of time where no motion is detected it should take\n",
    "#(in program cycles) for the program to declare that there is no movement\n",
    "MOVEMENT_DETECTED_PERSISTENCE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create capture object\n",
    "cap = cv2.VideoCapture(5) # Flush the stream\n",
    "cap.release()\n",
    "cap = cv2.VideoCapture(\"1.mp4\") # Then start the webcam\n",
    "# Deployment\\Vid\\alaykom_2.mp4\n",
    "# Init frame variables\n",
    "first_frame = None\n",
    "next_frame = None\n",
    "\n",
    "# Init display font and timeout counters\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "delay_counter = 0\n",
    "movement_persistent_counter = 0\n",
    "\n",
    "dim = (300, 300)\n",
    "p = ''\n",
    "wait = 0\n",
    "process_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('saydalya', 0.83472574), ('alhamd', 0.043138072), ('masged', 0.037743494), ('tamam', 0.020178216), ('salam', 0.013875334)]\n",
      "[('saydalya', 0.82027614), ('masged', 0.04436619), ('amel', 0.030610064), ('alhamd', 0.0239482), ('salam', 0.0232721)]\n",
      "[('saydalya', 0.8530785), ('masged', 0.027147565), ('salam', 0.02323856), ('alhamd', 0.020455156), ('tamam', 0.012516883)]\n",
      "[('saydalya', 0.8563655), ('salam', 0.031138064), ('alhamd', 0.027657626), ('masged', 0.022336852), ('amel', 0.012832711)]\n",
      "[('saydalya', 0.6811314), ('salam', 0.06528317), ('alhamd', 0.05143362), ('amel', 0.044286605), ('masged', 0.04234745)]\n",
      "[('saydalya', 0.7311544), ('masged', 0.06087138), ('alhamd', 0.047942422), ('salam', 0.039781213), ('amel', 0.03126263)]\n",
      "[('saydalya', 0.7306542), ('alhamd', 0.07474667), ('amel', 0.052180756), ('masged', 0.03161785), ('salam', 0.024760325)]\n",
      "[('saydalya', 0.8304806), ('masged', 0.037607852), ('alhamd', 0.029145839), ('ana', 0.022861145), ('salam', 0.018191751)]\n",
      "[('saydalya', 0.7659167), ('salam', 0.0424945), ('alhamd', 0.038552072), ('masged', 0.03674411), ('amel', 0.030487083)]\n",
      "CAPTURE ERROR\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    \n",
    "    wait += 1 \n",
    "    # Set transient motion detected as false\n",
    "    transient_movement_flag = False\n",
    "    \n",
    "    # Read frame\n",
    "    ret, frame = cap.read()\n",
    "    text = \"Unoccupied\"\n",
    "\n",
    "    # If there's an error in capturing\n",
    "    if not ret:\n",
    "        print(\"CAPTURE ERROR\")\n",
    "        break\n",
    "\n",
    "#     frame = cv2.flip(frame, 1)\n",
    "#     full_fram = frame.copy()\n",
    "#     full_fram = cv2.resize(frame, (800,600), interpolation = cv2.INTER_AREA)\n",
    "#     frame = cv2.resize(frame, dim, interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "#     sequence_list.append(frame)\n",
    "        \n",
    "#     if len(sequence_list) == realtime_frames:\n",
    "#         rescaledList = data.rescale_list(sequence_list, model_frames_num)\n",
    "#         p = predictions(rescaledList)\n",
    "#         sequence_list = []\n",
    "#         rescaledList = []\n",
    "        \n",
    "#     cv2.putText(full_fram, p, (250,550), cv2.FONT_HERSHEY_SIMPLEX, 2, (0,0,255), 2, cv2.LINE_AA)\n",
    "    \n",
    "    # Resize and save a greyscale version of the image    \n",
    "    frame = imutils.resize(frame, width = 750)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Blur it to remove camera noise (reducing false positives)\n",
    "    gray = cv2.GaussianBlur(gray, (21, 21), 0)\n",
    "\n",
    "    # If the first frame is nothing, initialise it\n",
    "    if first_frame is None: first_frame = gray    \n",
    "\n",
    "    delay_counter += 1\n",
    "\n",
    "    # Otherwise, set the first frame to compare as the previous frame\n",
    "    # But only if the counter reaches the appriopriate value\n",
    "    # The delay is to allow relatively slow motions to be counted as large\n",
    "    # motions if they're spread out far enough\n",
    "    if delay_counter > FRAMES_TO_PERSIST:\n",
    "        delay_counter = 0\n",
    "        first_frame = next_frame\n",
    "\n",
    "        \n",
    "    # Set the next frame to compare (the current frame)\n",
    "    next_frame = gray\n",
    "\n",
    "    # Compare the two frames, find the difference\n",
    "    frame_delta = cv2.absdiff(first_frame, next_frame)\n",
    "    thresh = cv2.threshold(frame_delta, 25, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "    # Fill in holes via dilate(), and find contours of the thesholds\n",
    "    thresh = cv2.dilate(thresh, None, iterations = 2)\n",
    "    _, cnts, _ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # loop over the contours\n",
    "    for c in cnts:\n",
    "\n",
    "        # Save the coordinates of all found contours\n",
    "        (x, y, w, h) = cv2.boundingRect(c)\n",
    "        \n",
    "        # If the contour is too small, ignore it, otherwise, there's transient\n",
    "        # movement\n",
    "        if cv2.contourArea(c) > MIN_SIZE_FOR_MOVEMENT:\n",
    "            transient_movement_flag = True\n",
    "            \n",
    "            # Draw a rectangle around big enough movements\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # The moment something moves momentarily, reset the persistent\n",
    "    # movement timer.\n",
    "    if transient_movement_flag == True:\n",
    "        movement_persistent_flag = True\n",
    "        movement_persistent_counter = MOVEMENT_DETECTED_PERSISTENCE\n",
    "\n",
    "    # As long as there was a recent transient movement, say a movement\n",
    "    # was detected    \n",
    "    if movement_persistent_counter > 0:\n",
    "        text = \"Movement Detected \" + str(movement_persistent_counter)\n",
    "        movement_persistent_counter -= 1\n",
    "    else:\n",
    "        text = \"No Movement Detected\"\n",
    "\n",
    "# q = multiprocessing.JoinableQueue()\n",
    "\n",
    "    if wait > 30:\n",
    "        if movement_persistent_counter > 85 :\n",
    "            pred_frame = cv2.resize(frame, dim, interpolation = cv2.INTER_AREA)\n",
    "            sequence_list.append(pred_frame)\n",
    "        else:\n",
    "            if len(sequence_list) > 30:\n",
    "                rescaledList = data.rescale_list(sequence_list, model_frames_num)\n",
    "                thread = threading.Thread(target = predictions, args=(rescaledList, model, ))\n",
    "                thread.daemon = True\n",
    "                thread.start()\n",
    "#                 p = predictions(rescaledList)\n",
    "                sequence_list = []\n",
    "                rescaledList = []\n",
    "\n",
    "        \n",
    "    # Print the text on the screen, and display the raw and processed video \n",
    "    # feeds\n",
    "    cv2.putText(frame, str(text), (10,35), font, 0.75, (255,255,255), 2, cv2.LINE_AA)\n",
    "    \n",
    "    # For if you want to show the individual video frames\n",
    "#    cv2.imshow(\"frame\", frame)\n",
    "#    cv2.imshow(\"delta\", frame_delta)\n",
    "    \n",
    "    # Convert the frame_delta to color for splicing\n",
    "    frame_delta = cv2.cvtColor(frame_delta, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Splice the two video frames together to make one long horizontal one\n",
    "    cv2.imshow(\"frame\", np.hstack((frame_delta, frame)))\n",
    "\n",
    "    # Interrupt trigger by pressing q to quit the open CV program\n",
    "    ch = cv2.waitKey(1)\n",
    "    if ch & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "# Cleanup when closed\n",
    "# cv2.waitKey(0)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import threading\n",
    "# import time\n",
    "\n",
    "\n",
    "# class ThreadingExample(object):\n",
    "#     \"\"\" Threading example class\n",
    "#     The run() method will be started and it will run in the background\n",
    "#     until the application exits.\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, interval=1):\n",
    "#         \"\"\" Constructor\n",
    "#         :type interval: int\n",
    "#         :param interval: Check interval, in seconds\n",
    "#         \"\"\"\n",
    "#         self.interval = interval\n",
    "\n",
    "#         thread = threading.Thread(target=self.run, args=())\n",
    "#         thread.daemon = True                            # Daemonize thread\n",
    "#         thread.start()                                  # Start the execution\n",
    "\n",
    "#     def run(self):\n",
    "#         \"\"\" Method that runs forever \"\"\"\n",
    "#         while True:\n",
    "#             # Do something\n",
    "#             print('Doing something imporant in the background')\n",
    "\n",
    "#             time.sleep(self.interval)\n",
    "\n",
    "# example = ThreadingExample()\n",
    "# time.sleep(3)\n",
    "# print('Checkpoint')\n",
    "# time.sleep(2)\n",
    "# print('Bye')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
